{"ast":null,"code":"// const syllable = require(\"syllable\");         // npm i syllable\n// const flesch   = require(\"flesch-kincaid\");   // npm i flesch-kincaid\n// const uniq     = require(\"lodash/uniq\");\n\n// exports.calcMetrics = (txt = \"\") => {\n//   const words       = txt.trim().split(/\\s+/).filter(Boolean);\n//   const sentences   = txt.split(/[.!?]+/).filter(Boolean);\n//   const chars       = txt.length;\n//   const charsNoSp   = txt.replace(/\\s+/g, \"\").length;\n//   const syllables   = words.reduce((s, w) => s + syllable(w), 0);\n\n//   const fk          = flesch({ sentence: sentences.length || 1,\n//                                word: words.length || 1,\n//                                syllable: syllables || 1 });\n\n//   return {\n//     fleschReadingEase:  fk.ease,\n//     fleschKincaidGrade: fk.grade,\n//     lexicalDensity:     uniq(words).length / words.length || 0,\n//     wordCount:          words.length,\n//     uniqueWords:        uniq(words).length,\n//     sentenceCount:      sentences.length,\n//     avgSentenceLength:  words.length / (sentences.length || 1),\n//     charsWithSpaces:    chars,\n//     charsWithoutSpaces: charsNoSp,\n//     avgCharsPerWord:    charsNoSp / (words.length || 1),\n//     syllableCount:      syllables,\n//     avgSyllablesPerWord: syllables / (words.length || 1),\n//   };\n// };\n\n// exports.diffStats = (a = \"\", b = \"\") => {\n//   const dmp   = new (require(\"diff-match-patch\"))();\n//   const diffs = dmp.diff_main(a, b);\n//   dmp.diff_cleanupSemantic(diffs);\n\n//   let insertions = 0,\n//       deletions  = 0;\n\n//   diffs.forEach(([op, txt]) => {\n//     if (op === 1) insertions += txt.trim().split(/\\s+/).length;\n//     if (op === -1) deletions  += txt.trim().split(/\\s+/).length;\n//   });\n\n//   return {\n//     distance: dmp.diff_levenshtein(diffs),\n//     insertions,\n//     deletions,\n//   };\n// };\n\n/* utils/textMetrics.js\n   ------------------------------------------------------------------------ */\nconst raw = require(\"syllable\"); // whatever shape it is\n/* ðŸ”¹ one line that never fails */\nconst syllable = typeof raw === \"function\" ? raw : raw.default || raw.syllable || (() => 0); // fallback = dummy fn\n\n//  const fk    = require(\"flesch-kincaid\");\n\nconst rawFk = require(\"flesch-kincaid\");\nconst fk = typeof rawFk === \"function\" ? rawFk : rawFk.default || rawFk.fk || (() => 0); // fallback dummy fn\n\nconst uniq = require(\"lodash/uniq\");\nconst DMP = require(\"diff-match-patch\");\n\n/* safe division to avoid NaN / Infinity */\nconst div = (n, d) => d ? n / d : 0;\n\n/* ---------------------------------------------------------------------- */\nexports.calcMetrics = (txt = \"\") => {\n  const words = txt.trim().split(/\\s+/).filter(Boolean);\n  const sentences = txt.split(/[.!?]+/).filter(Boolean);\n  const charsWS = txt.length;\n  const charsNoWS = txt.replace(/\\s+/g, \"\").length;\n  const syllables = words.reduce((s, w) => s + syllable(w), 0);\n\n  /* FK grade from package */\n  const fkGrade = fk({\n    sentence: sentences.length || 1,\n    word: words.length || 1,\n    syllable: syllables || 1\n  });\n\n  /* FRE ease â€“ manual formula */\n  const freEase = 206.835 - 1.015 * div(words.length, sentences.length || 1) - 84.6 * div(syllables, words.length || 1);\n  return {\n    fleschReadingEase: +freEase.toFixed(2),\n    fleschKincaidGrade: +fkGrade.toFixed(2),\n    lexicalDensity: div(uniq(words).length, words.length),\n    wordCount: words.length,\n    uniqueWords: uniq(words).length,\n    sentenceCount: sentences.length,\n    avgSentenceLength: +div(words.length, sentences.length || 1).toFixed(2),\n    charsWithSpaces: charsWS,\n    charsWithoutSpaces: charsNoWS,\n    avgCharsPerWord: +div(charsNoWS, words.length || 1).toFixed(2),\n    syllableCount: syllables,\n    avgSyllablesPerWord: +div(syllables, words.length || 1).toFixed(2)\n  };\n};\n\n/* ---------------------------------------------------------------------- */\nexports.diffStats = (a = \"\", b = \"\") => {\n  const dmp = new DMP();\n  const diffs = dmp.diff_main(a, b);\n  dmp.diff_cleanupSemantic(diffs);\n  let insertions = 0,\n    deletions = 0;\n  diffs.forEach(([op, txt]) => {\n    const delta = txt.trim().split(/\\s+/).filter(Boolean).length;\n    if (op === 1) insertions += delta;\n    if (op === -1) deletions += delta;\n  });\n  return {\n    distance: dmp.diff_levenshtein(diffs),\n    insertions,\n    deletions\n  };\n};\n\n/* utils/textMetrics.js\n   -------------------------------------------------------------------------- */\n\n//  const _syllable = require(\"syllable\");            // â‰¥4.x is ESMâ€‘only\n//  /* if it's an ESM default export grab it, otherwise use the value directly */\n//  const syllable  = typeof _syllable === \"function\" ? _syllable : _syllable.default;\n\n//  const fk        = require(\"flesch-kincaid\");\n//  const uniq      = require(\"lodash/uniq\");\n//  const DiffMatchPatch = require(\"diff-match-patch\");\n\n//  /* small helper for safe division (avoids NaN / Infinity) */\n//  const safeDiv = (num, den) => (den ? num / den : 0);\n\n//  /* --------------------------------------------------------------------------\n//   * MAIN TEXTâ€‘METRIC AGGREGATOR\n//   * ------------------------------------------------------------------------ */\n//  exports.calcMetrics = (txt = \"\") => {\n//    const words     = txt.trim().split(/\\s+/).filter(Boolean);\n//    const sentences = txt.split(/[.!?]+/).filter(Boolean);\n//    const charsWithSpaces    = txt.length;\n//    const charsWithoutSpaces = txt.replace(/\\s+/g, \"\").length;\n//    const syllableCount      = words.reduce((acc, w) => acc + syllable(w), 0);\n\n//    /* FK grade â€“ package returns only grade level */\n//    const fkGrade = fk({\n//      sentence : sentences.length || 1,\n//      word     : words.length      || 1,\n//      syllable : syllableCount     || 1,\n//    });\n\n//    /* Fleschâ€‘Readingâ€‘Ease â€“ compute ourselves */\n//    const freEase =\n//      206.835 -\n//      1.015 * safeDiv(words.length,     sentences.length || 1) -\n//      84.6  * safeDiv(syllableCount,    words.length     || 1);\n\n//    return {\n//      /* headline readability scores */\n//      fleschReadingEase   : Number(freEase.toFixed(2)),\n//      fleschKincaidGrade  : Number(fkGrade.toFixed(2)),\n\n//      /* lexical / structural stats */\n//      lexicalDensity      : safeDiv(uniq(words).length, words.length),\n//      wordCount           : words.length,\n//      uniqueWords         : uniq(words).length,\n//      sentenceCount       : sentences.length,\n//      avgSentenceLength   : Number(\n//        safeDiv(words.length, sentences.length || 1).toFixed(2)\n//      ),\n\n//      /* characterâ€‘level stats */\n//      charsWithSpaces,\n//      charsWithoutSpaces,\n//      avgCharsPerWord     : Number(\n//        safeDiv(charsWithoutSpaces, words.length || 1).toFixed(2)\n//      ),\n\n//      /* syllableâ€‘level stats */\n//      syllableCount,\n//      avgSyllablesPerWord : Number(\n//        safeDiv(syllableCount, words.length || 1).toFixed(2)\n//      ),\n//    };\n//  };\n\n//  /* --------------------------------------------------------------------------\n//   * DIFFâ€‘BASED EDIT DISTANCE / INSERTIONS / DELETIONS\n//   * ------------------------------------------------------------------------ */\n//  exports.diffStats = (a = \"\", b = \"\") => {\n//    const dmp   = new DiffMatchPatch();\n//    const diffs = dmp.diff_main(a, b);\n//    dmp.diff_cleanupSemantic(diffs);\n\n//    let insertions = 0;\n//    let deletions  = 0;\n\n//    diffs.forEach(([op, txt]) => {\n//      const delta = txt.trim().split(/\\s+/).filter(Boolean).length;\n//      if (op ===  1) insertions += delta;  // added in b\n//      if (op === -1) deletions  += delta;  // removed from a\n//    });\n\n//    return {\n//      distance   : dmp.diff_levenshtein(diffs),\n//      insertions,\n//      deletions,\n//    };\n//  };","map":{"version":3,"names":["raw","require","syllable","default","rawFk","fk","uniq","DMP","div","n","d","exports","calcMetrics","txt","words","trim","split","filter","Boolean","sentences","charsWS","length","charsNoWS","replace","syllables","reduce","s","w","fkGrade","sentence","word","freEase","fleschReadingEase","toFixed","fleschKincaidGrade","lexicalDensity","wordCount","uniqueWords","sentenceCount","avgSentenceLength","charsWithSpaces","charsWithoutSpaces","avgCharsPerWord","syllableCount","avgSyllablesPerWord","diffStats","a","b","dmp","diffs","diff_main","diff_cleanupSemantic","insertions","deletions","forEach","op","delta","distance","diff_levenshtein"],"sources":["/Users/anukumar/Desktop/Spring2025/local-textsimplification/client/src/utils/textMetrics.js"],"sourcesContent":["// const syllable = require(\"syllable\");         // npm i syllable\n// const flesch   = require(\"flesch-kincaid\");   // npm i flesch-kincaid\n// const uniq     = require(\"lodash/uniq\");\n\n// exports.calcMetrics = (txt = \"\") => {\n//   const words       = txt.trim().split(/\\s+/).filter(Boolean);\n//   const sentences   = txt.split(/[.!?]+/).filter(Boolean);\n//   const chars       = txt.length;\n//   const charsNoSp   = txt.replace(/\\s+/g, \"\").length;\n//   const syllables   = words.reduce((s, w) => s + syllable(w), 0);\n\n//   const fk          = flesch({ sentence: sentences.length || 1,\n//                                word: words.length || 1,\n//                                syllable: syllables || 1 });\n\n//   return {\n//     fleschReadingEase:  fk.ease,\n//     fleschKincaidGrade: fk.grade,\n//     lexicalDensity:     uniq(words).length / words.length || 0,\n//     wordCount:          words.length,\n//     uniqueWords:        uniq(words).length,\n//     sentenceCount:      sentences.length,\n//     avgSentenceLength:  words.length / (sentences.length || 1),\n//     charsWithSpaces:    chars,\n//     charsWithoutSpaces: charsNoSp,\n//     avgCharsPerWord:    charsNoSp / (words.length || 1),\n//     syllableCount:      syllables,\n//     avgSyllablesPerWord: syllables / (words.length || 1),\n//   };\n// };\n\n// exports.diffStats = (a = \"\", b = \"\") => {\n//   const dmp   = new (require(\"diff-match-patch\"))();\n//   const diffs = dmp.diff_main(a, b);\n//   dmp.diff_cleanupSemantic(diffs);\n\n//   let insertions = 0,\n//       deletions  = 0;\n\n//   diffs.forEach(([op, txt]) => {\n//     if (op === 1) insertions += txt.trim().split(/\\s+/).length;\n//     if (op === -1) deletions  += txt.trim().split(/\\s+/).length;\n//   });\n\n//   return {\n//     distance: dmp.diff_levenshtein(diffs),\n//     insertions,\n//     deletions,\n//   };\n// };\n\n/* utils/textMetrics.js\n   ------------------------------------------------------------------------ */\n   const raw = require(\"syllable\");                 // whatever shape it is\n   /* ðŸ”¹ one line that never fails */\n   const syllable =\n     typeof raw === \"function\"\n       ? raw\n       : raw.default || raw.syllable || (() => 0);  // fallback = dummy fn\n   \n  //  const fk    = require(\"flesch-kincaid\");\n\n   const rawFk = require(\"flesch-kincaid\");\n\nconst fk =\n  typeof rawFk === \"function\"\n    ? rawFk\n    : rawFk.default || rawFk.fk || (() => 0);   // fallback dummy fn\n\n   const uniq  = require(\"lodash/uniq\");\n   const DMP   = require(\"diff-match-patch\");\n   \n   /* safe division to avoid NaN / Infinity */\n   const div = (n, d) => (d ? n / d : 0);\n   \n   /* ---------------------------------------------------------------------- */\n   exports.calcMetrics = (txt = \"\") => {\n     const words      = txt.trim().split(/\\s+/).filter(Boolean);\n     const sentences  = txt.split(/[.!?]+/).filter(Boolean);\n     const charsWS    = txt.length;\n     const charsNoWS  = txt.replace(/\\s+/g, \"\").length;\n     const syllables  = words.reduce((s, w) => s + syllable(w), 0);\n   \n     /* FK grade from package */\n     const fkGrade = fk({\n       sentence : sentences.length || 1,\n       word     : words.length     || 1,\n       syllable : syllables        || 1,\n     });\n   \n     /* FRE ease â€“ manual formula */\n     const freEase =\n       206.835 -\n       1.015 * div(words.length, sentences.length || 1) -\n       84.6  * div(syllables,   words.length     || 1);\n   \n     return {\n       fleschReadingEase   : +freEase.toFixed(2),\n       fleschKincaidGrade  : +fkGrade.toFixed(2),\n       lexicalDensity      : div(uniq(words).length, words.length),\n       wordCount           : words.length,\n       uniqueWords         : uniq(words).length,\n       sentenceCount       : sentences.length,\n       avgSentenceLength   : +div(words.length, sentences.length || 1).toFixed(2),\n       charsWithSpaces     : charsWS,\n       charsWithoutSpaces  : charsNoWS,\n       avgCharsPerWord     : +div(charsNoWS, words.length || 1).toFixed(2),\n       syllableCount       : syllables,\n       avgSyllablesPerWord : +div(syllables, words.length || 1).toFixed(2),\n     };\n   };\n   \n   /* ---------------------------------------------------------------------- */\n   exports.diffStats = (a = \"\", b = \"\") => {\n     const dmp   = new DMP();\n     const diffs = dmp.diff_main(a, b);\n     dmp.diff_cleanupSemantic(diffs);\n   \n     let insertions = 0,\n         deletions  = 0;\n   \n     diffs.forEach(([op, txt]) => {\n       const delta = txt.trim().split(/\\s+/).filter(Boolean).length;\n       if (op ===  1) insertions += delta;\n       if (op === -1) deletions  += delta;\n     });\n   \n     return {\n       distance   : dmp.diff_levenshtein(diffs),\n       insertions,\n       deletions,\n     };\n   };\n   \n/* utils/textMetrics.js\n   -------------------------------------------------------------------------- */\n\n  //  const _syllable = require(\"syllable\");            // â‰¥4.x is ESMâ€‘only\n  //  /* if it's an ESM default export grab it, otherwise use the value directly */\n  //  const syllable  = typeof _syllable === \"function\" ? _syllable : _syllable.default;\n   \n  //  const fk        = require(\"flesch-kincaid\");\n  //  const uniq      = require(\"lodash/uniq\");\n  //  const DiffMatchPatch = require(\"diff-match-patch\");\n   \n  //  /* small helper for safe division (avoids NaN / Infinity) */\n  //  const safeDiv = (num, den) => (den ? num / den : 0);\n   \n  //  /* --------------------------------------------------------------------------\n  //   * MAIN TEXTâ€‘METRIC AGGREGATOR\n  //   * ------------------------------------------------------------------------ */\n  //  exports.calcMetrics = (txt = \"\") => {\n  //    const words     = txt.trim().split(/\\s+/).filter(Boolean);\n  //    const sentences = txt.split(/[.!?]+/).filter(Boolean);\n  //    const charsWithSpaces    = txt.length;\n  //    const charsWithoutSpaces = txt.replace(/\\s+/g, \"\").length;\n  //    const syllableCount      = words.reduce((acc, w) => acc + syllable(w), 0);\n   \n  //    /* FK grade â€“ package returns only grade level */\n  //    const fkGrade = fk({\n  //      sentence : sentences.length || 1,\n  //      word     : words.length      || 1,\n  //      syllable : syllableCount     || 1,\n  //    });\n   \n  //    /* Fleschâ€‘Readingâ€‘Ease â€“ compute ourselves */\n  //    const freEase =\n  //      206.835 -\n  //      1.015 * safeDiv(words.length,     sentences.length || 1) -\n  //      84.6  * safeDiv(syllableCount,    words.length     || 1);\n   \n  //    return {\n  //      /* headline readability scores */\n  //      fleschReadingEase   : Number(freEase.toFixed(2)),\n  //      fleschKincaidGrade  : Number(fkGrade.toFixed(2)),\n   \n  //      /* lexical / structural stats */\n  //      lexicalDensity      : safeDiv(uniq(words).length, words.length),\n  //      wordCount           : words.length,\n  //      uniqueWords         : uniq(words).length,\n  //      sentenceCount       : sentences.length,\n  //      avgSentenceLength   : Number(\n  //        safeDiv(words.length, sentences.length || 1).toFixed(2)\n  //      ),\n   \n  //      /* characterâ€‘level stats */\n  //      charsWithSpaces,\n  //      charsWithoutSpaces,\n  //      avgCharsPerWord     : Number(\n  //        safeDiv(charsWithoutSpaces, words.length || 1).toFixed(2)\n  //      ),\n   \n  //      /* syllableâ€‘level stats */\n  //      syllableCount,\n  //      avgSyllablesPerWord : Number(\n  //        safeDiv(syllableCount, words.length || 1).toFixed(2)\n  //      ),\n  //    };\n  //  };\n   \n  //  /* --------------------------------------------------------------------------\n  //   * DIFFâ€‘BASED EDIT DISTANCE / INSERTIONS / DELETIONS\n  //   * ------------------------------------------------------------------------ */\n  //  exports.diffStats = (a = \"\", b = \"\") => {\n  //    const dmp   = new DiffMatchPatch();\n  //    const diffs = dmp.diff_main(a, b);\n  //    dmp.diff_cleanupSemantic(diffs);\n   \n  //    let insertions = 0;\n  //    let deletions  = 0;\n   \n  //    diffs.forEach(([op, txt]) => {\n  //      const delta = txt.trim().split(/\\s+/).filter(Boolean).length;\n  //      if (op ===  1) insertions += delta;  // added in b\n  //      if (op === -1) deletions  += delta;  // removed from a\n  //    });\n   \n  //    return {\n  //      distance   : dmp.diff_levenshtein(diffs),\n  //      insertions,\n  //      deletions,\n  //    };\n  //  };\n   "],"mappings":"AAAA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACG,MAAMA,GAAG,GAAGC,OAAO,CAAC,UAAU,CAAC,CAAC,CAAiB;AACjD;AACA,MAAMC,QAAQ,GACZ,OAAOF,GAAG,KAAK,UAAU,GACrBA,GAAG,GACHA,GAAG,CAACG,OAAO,IAAIH,GAAG,CAACE,QAAQ,KAAK,MAAM,CAAC,CAAC,CAAC,CAAE;;AAElD;;AAEC,MAAME,KAAK,GAAGH,OAAO,CAAC,gBAAgB,CAAC;AAE1C,MAAMI,EAAE,GACN,OAAOD,KAAK,KAAK,UAAU,GACvBA,KAAK,GACLA,KAAK,CAACD,OAAO,IAAIC,KAAK,CAACC,EAAE,KAAK,MAAM,CAAC,CAAC,CAAC,CAAG;;AAE7C,MAAMC,IAAI,GAAIL,OAAO,CAAC,aAAa,CAAC;AACpC,MAAMM,GAAG,GAAKN,OAAO,CAAC,kBAAkB,CAAC;;AAEzC;AACA,MAAMO,GAAG,GAAGA,CAACC,CAAC,EAAEC,CAAC,KAAMA,CAAC,GAAGD,CAAC,GAAGC,CAAC,GAAG,CAAE;;AAErC;AACAC,OAAO,CAACC,WAAW,GAAG,CAACC,GAAG,GAAG,EAAE,KAAK;EAClC,MAAMC,KAAK,GAAQD,GAAG,CAACE,IAAI,CAAC,CAAC,CAACC,KAAK,CAAC,KAAK,CAAC,CAACC,MAAM,CAACC,OAAO,CAAC;EAC1D,MAAMC,SAAS,GAAIN,GAAG,CAACG,KAAK,CAAC,QAAQ,CAAC,CAACC,MAAM,CAACC,OAAO,CAAC;EACtD,MAAME,OAAO,GAAMP,GAAG,CAACQ,MAAM;EAC7B,MAAMC,SAAS,GAAIT,GAAG,CAACU,OAAO,CAAC,MAAM,EAAE,EAAE,CAAC,CAACF,MAAM;EACjD,MAAMG,SAAS,GAAIV,KAAK,CAACW,MAAM,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKD,CAAC,GAAGxB,QAAQ,CAACyB,CAAC,CAAC,EAAE,CAAC,CAAC;;EAE7D;EACA,MAAMC,OAAO,GAAGvB,EAAE,CAAC;IACjBwB,QAAQ,EAAGV,SAAS,CAACE,MAAM,IAAI,CAAC;IAChCS,IAAI,EAAOhB,KAAK,CAACO,MAAM,IAAQ,CAAC;IAChCnB,QAAQ,EAAGsB,SAAS,IAAW;EACjC,CAAC,CAAC;;EAEF;EACA,MAAMO,OAAO,GACX,OAAO,GACP,KAAK,GAAGvB,GAAG,CAACM,KAAK,CAACO,MAAM,EAAEF,SAAS,CAACE,MAAM,IAAI,CAAC,CAAC,GAChD,IAAI,GAAIb,GAAG,CAACgB,SAAS,EAAIV,KAAK,CAACO,MAAM,IAAQ,CAAC,CAAC;EAEjD,OAAO;IACLW,iBAAiB,EAAK,CAACD,OAAO,CAACE,OAAO,CAAC,CAAC,CAAC;IACzCC,kBAAkB,EAAI,CAACN,OAAO,CAACK,OAAO,CAAC,CAAC,CAAC;IACzCE,cAAc,EAAQ3B,GAAG,CAACF,IAAI,CAACQ,KAAK,CAAC,CAACO,MAAM,EAAEP,KAAK,CAACO,MAAM,CAAC;IAC3De,SAAS,EAAatB,KAAK,CAACO,MAAM;IAClCgB,WAAW,EAAW/B,IAAI,CAACQ,KAAK,CAAC,CAACO,MAAM;IACxCiB,aAAa,EAASnB,SAAS,CAACE,MAAM;IACtCkB,iBAAiB,EAAK,CAAC/B,GAAG,CAACM,KAAK,CAACO,MAAM,EAAEF,SAAS,CAACE,MAAM,IAAI,CAAC,CAAC,CAACY,OAAO,CAAC,CAAC,CAAC;IAC1EO,eAAe,EAAOpB,OAAO;IAC7BqB,kBAAkB,EAAInB,SAAS;IAC/BoB,eAAe,EAAO,CAAClC,GAAG,CAACc,SAAS,EAAER,KAAK,CAACO,MAAM,IAAI,CAAC,CAAC,CAACY,OAAO,CAAC,CAAC,CAAC;IACnEU,aAAa,EAASnB,SAAS;IAC/BoB,mBAAmB,EAAG,CAACpC,GAAG,CAACgB,SAAS,EAAEV,KAAK,CAACO,MAAM,IAAI,CAAC,CAAC,CAACY,OAAO,CAAC,CAAC;EACpE,CAAC;AACH,CAAC;;AAED;AACAtB,OAAO,CAACkC,SAAS,GAAG,CAACC,CAAC,GAAG,EAAE,EAAEC,CAAC,GAAG,EAAE,KAAK;EACtC,MAAMC,GAAG,GAAK,IAAIzC,GAAG,CAAC,CAAC;EACvB,MAAM0C,KAAK,GAAGD,GAAG,CAACE,SAAS,CAACJ,CAAC,EAAEC,CAAC,CAAC;EACjCC,GAAG,CAACG,oBAAoB,CAACF,KAAK,CAAC;EAE/B,IAAIG,UAAU,GAAG,CAAC;IACdC,SAAS,GAAI,CAAC;EAElBJ,KAAK,CAACK,OAAO,CAAC,CAAC,CAACC,EAAE,EAAE1C,GAAG,CAAC,KAAK;IAC3B,MAAM2C,KAAK,GAAG3C,GAAG,CAACE,IAAI,CAAC,CAAC,CAACC,KAAK,CAAC,KAAK,CAAC,CAACC,MAAM,CAACC,OAAO,CAAC,CAACG,MAAM;IAC5D,IAAIkC,EAAE,KAAM,CAAC,EAAEH,UAAU,IAAII,KAAK;IAClC,IAAID,EAAE,KAAK,CAAC,CAAC,EAAEF,SAAS,IAAKG,KAAK;EACpC,CAAC,CAAC;EAEF,OAAO;IACLC,QAAQ,EAAKT,GAAG,CAACU,gBAAgB,CAACT,KAAK,CAAC;IACxCG,UAAU;IACVC;EACF,CAAC;AACH,CAAC;;AAEJ;AACA;;AAEE;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}