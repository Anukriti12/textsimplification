{"ast":null,"code":"// const syllable = require(\"syllable\");         // npm i syllable\n// const flesch   = require(\"flesch-kincaid\");   // npm i flesch-kincaid\n// const uniq     = require(\"lodash/uniq\");\n\n// exports.calcMetrics = (txt = \"\") => {\n//   const words       = txt.trim().split(/\\s+/).filter(Boolean);\n//   const sentences   = txt.split(/[.!?]+/).filter(Boolean);\n//   const chars       = txt.length;\n//   const charsNoSp   = txt.replace(/\\s+/g, \"\").length;\n//   const syllables   = words.reduce((s, w) => s + syllable(w), 0);\n\n//   const fk          = flesch({ sentence: sentences.length || 1,\n//                                word: words.length || 1,\n//                                syllable: syllables || 1 });\n\n//   return {\n//     fleschReadingEase:  fk.ease,\n//     fleschKincaidGrade: fk.grade,\n//     lexicalDensity:     uniq(words).length / words.length || 0,\n//     wordCount:          words.length,\n//     uniqueWords:        uniq(words).length,\n//     sentenceCount:      sentences.length,\n//     avgSentenceLength:  words.length / (sentences.length || 1),\n//     charsWithSpaces:    chars,\n//     charsWithoutSpaces: charsNoSp,\n//     avgCharsPerWord:    charsNoSp / (words.length || 1),\n//     syllableCount:      syllables,\n//     avgSyllablesPerWord: syllables / (words.length || 1),\n//   };\n// };\n\n// exports.diffStats = (a = \"\", b = \"\") => {\n//   const dmp   = new (require(\"diff-match-patch\"))();\n//   const diffs = dmp.diff_main(a, b);\n//   dmp.diff_cleanupSemantic(diffs);\n\n//   let insertions = 0,\n//       deletions  = 0;\n\n//   diffs.forEach(([op, txt]) => {\n//     if (op === 1) insertions += txt.trim().split(/\\s+/).length;\n//     if (op === -1) deletions  += txt.trim().split(/\\s+/).length;\n//   });\n\n//   return {\n//     distance: dmp.diff_levenshtein(diffs),\n//     insertions,\n//     deletions,\n//   };\n// };\n\n/* utils/textMetrics.js\n   -------------------------------------------------------------------------- */\n\nconst syllable = require(\"syllable\"); // npm i syllable\nconst fk = require(\"flesch-kincaid\"); // npm i flesch-kincaid\nconst uniq = require(\"lodash/uniq\");\nconst DiffMatchPatch = require(\"diff-match-patch\");\n\n/* small helper for safe division */\nconst safeDiv = (num, den) => den ? num / den : 0;\n\n/* --------------------------------------------------------------------------\n * MAIN TEXT‑METRIC AGGREGATOR\n * ------------------------------------------------------------------------ */\nexports.calcMetrics = (txt = \"\") => {\n  const words = txt.trim().split(/\\s+/).filter(Boolean);\n  const sentences = txt.split(/[.!?]+/).filter(Boolean);\n  const charsWithSpaces = txt.length;\n  const charsWithoutSpaces = txt.replace(/\\s+/g, \"\").length;\n  const syllableCount = words.reduce((acc, w) => acc + syllable(w), 0);\n\n  /* FK grade – package returns only grade level */\n  const fkGrade = fk({\n    sentence: sentences.length || 1,\n    word: words.length || 1,\n    syllable: syllableCount || 1\n  });\n\n  /* Flesch‑Reading‑Ease – compute ourselves */\n  const freEase = 206.835 - 1.015 * safeDiv(words.length, sentences.length || 1) - 84.6 * safeDiv(syllableCount, words.length || 1);\n  return {\n    /* headline readability scores */\n    fleschReadingEase: Number(freEase.toFixed(2)),\n    fleschKincaidGrade: Number(fkGrade.toFixed(2)),\n    /* lexical / structural stats */\n    lexicalDensity: safeDiv(uniq(words).length, words.length),\n    wordCount: words.length,\n    uniqueWords: uniq(words).length,\n    sentenceCount: sentences.length,\n    avgSentenceLength: Number(safeDiv(words.length, sentences.length || 1).toFixed(2)),\n    /* character‑level stats */\n    charsWithSpaces,\n    charsWithoutSpaces,\n    avgCharsPerWord: Number(safeDiv(charsWithoutSpaces, words.length || 1).toFixed(2)),\n    /* syllable‑level stats */\n    syllableCount,\n    avgSyllablesPerWord: Number(safeDiv(syllableCount, words.length || 1).toFixed(2))\n  };\n};\n\n/* --------------------------------------------------------------------------\n * DIFF‑BASED EDIT DISTANCE / INSERTIONS / DELETIONS\n * ------------------------------------------------------------------------ */\nexports.diffStats = (a = \"\", b = \"\") => {\n  const dmp = new DiffMatchPatch();\n  const diffs = dmp.diff_main(a, b);\n  dmp.diff_cleanupSemantic(diffs);\n  let insertions = 0;\n  let deletions = 0;\n  diffs.forEach(([op, txt]) => {\n    const delta = txt.trim().split(/\\s+/).filter(Boolean).length;\n    if (op === 1) insertions += delta; // added in b\n    if (op === -1) deletions += delta; // removed from a\n  });\n  return {\n    distance: dmp.diff_levenshtein(diffs),\n    insertions,\n    deletions\n  };\n};","map":{"version":3,"names":["syllable","require","fk","uniq","DiffMatchPatch","safeDiv","num","den","exports","calcMetrics","txt","words","trim","split","filter","Boolean","sentences","charsWithSpaces","length","charsWithoutSpaces","replace","syllableCount","reduce","acc","w","fkGrade","sentence","word","freEase","fleschReadingEase","Number","toFixed","fleschKincaidGrade","lexicalDensity","wordCount","uniqueWords","sentenceCount","avgSentenceLength","avgCharsPerWord","avgSyllablesPerWord","diffStats","a","b","dmp","diffs","diff_main","diff_cleanupSemantic","insertions","deletions","forEach","op","delta","distance","diff_levenshtein"],"sources":["/Users/anukumar/Desktop/Spring2025/local-textsimplification/client/src/utils/textMetrics.js"],"sourcesContent":["// const syllable = require(\"syllable\");         // npm i syllable\n// const flesch   = require(\"flesch-kincaid\");   // npm i flesch-kincaid\n// const uniq     = require(\"lodash/uniq\");\n\n// exports.calcMetrics = (txt = \"\") => {\n//   const words       = txt.trim().split(/\\s+/).filter(Boolean);\n//   const sentences   = txt.split(/[.!?]+/).filter(Boolean);\n//   const chars       = txt.length;\n//   const charsNoSp   = txt.replace(/\\s+/g, \"\").length;\n//   const syllables   = words.reduce((s, w) => s + syllable(w), 0);\n\n//   const fk          = flesch({ sentence: sentences.length || 1,\n//                                word: words.length || 1,\n//                                syllable: syllables || 1 });\n\n//   return {\n//     fleschReadingEase:  fk.ease,\n//     fleschKincaidGrade: fk.grade,\n//     lexicalDensity:     uniq(words).length / words.length || 0,\n//     wordCount:          words.length,\n//     uniqueWords:        uniq(words).length,\n//     sentenceCount:      sentences.length,\n//     avgSentenceLength:  words.length / (sentences.length || 1),\n//     charsWithSpaces:    chars,\n//     charsWithoutSpaces: charsNoSp,\n//     avgCharsPerWord:    charsNoSp / (words.length || 1),\n//     syllableCount:      syllables,\n//     avgSyllablesPerWord: syllables / (words.length || 1),\n//   };\n// };\n\n// exports.diffStats = (a = \"\", b = \"\") => {\n//   const dmp   = new (require(\"diff-match-patch\"))();\n//   const diffs = dmp.diff_main(a, b);\n//   dmp.diff_cleanupSemantic(diffs);\n\n//   let insertions = 0,\n//       deletions  = 0;\n\n//   diffs.forEach(([op, txt]) => {\n//     if (op === 1) insertions += txt.trim().split(/\\s+/).length;\n//     if (op === -1) deletions  += txt.trim().split(/\\s+/).length;\n//   });\n\n//   return {\n//     distance: dmp.diff_levenshtein(diffs),\n//     insertions,\n//     deletions,\n//   };\n// };\n\n/* utils/textMetrics.js\n   -------------------------------------------------------------------------- */\n\n   const syllable = require(\"syllable\");        // npm i syllable\n   const fk       = require(\"flesch-kincaid\");  // npm i flesch-kincaid\n   const uniq     = require(\"lodash/uniq\");\n   const DiffMatchPatch = require(\"diff-match-patch\");\n   \n   /* small helper for safe division */\n   const safeDiv = (num, den) => (den ? num / den : 0);\n   \n   /* --------------------------------------------------------------------------\n    * MAIN TEXT‑METRIC AGGREGATOR\n    * ------------------------------------------------------------------------ */\n   exports.calcMetrics = (txt = \"\") => {\n     const words     = txt.trim().split(/\\s+/).filter(Boolean);\n     const sentences = txt.split(/[.!?]+/).filter(Boolean);\n     const charsWithSpaces    = txt.length;\n     const charsWithoutSpaces = txt.replace(/\\s+/g, \"\").length;\n     const syllableCount      = words.reduce((acc, w) => acc + syllable(w), 0);\n   \n     /* FK grade – package returns only grade level */\n     const fkGrade = fk({\n       sentence : sentences.length || 1,\n       word     : words.length      || 1,\n       syllable : syllableCount     || 1,\n     });\n   \n     /* Flesch‑Reading‑Ease – compute ourselves */\n     const freEase =\n       206.835 -\n       1.015 * safeDiv(words.length,     sentences.length || 1) -\n       84.6  * safeDiv(syllableCount,    words.length     || 1);\n   \n     return {\n       /* headline readability scores */\n       fleschReadingEase   : Number(freEase.toFixed(2)),\n       fleschKincaidGrade  : Number(fkGrade.toFixed(2)),\n   \n       /* lexical / structural stats */\n       lexicalDensity      : safeDiv(uniq(words).length, words.length),\n       wordCount           : words.length,\n       uniqueWords         : uniq(words).length,\n       sentenceCount       : sentences.length,\n       avgSentenceLength   : Number(\n         safeDiv(words.length, sentences.length || 1).toFixed(2)\n       ),\n   \n       /* character‑level stats */\n       charsWithSpaces,\n       charsWithoutSpaces,\n       avgCharsPerWord     : Number(\n         safeDiv(charsWithoutSpaces, words.length || 1).toFixed(2)\n       ),\n   \n       /* syllable‑level stats */\n       syllableCount,\n       avgSyllablesPerWord : Number(\n         safeDiv(syllableCount, words.length || 1).toFixed(2)\n       ),\n     };\n   };\n   \n   /* --------------------------------------------------------------------------\n    * DIFF‑BASED EDIT DISTANCE / INSERTIONS / DELETIONS\n    * ------------------------------------------------------------------------ */\n   exports.diffStats = (a = \"\", b = \"\") => {\n     const dmp   = new DiffMatchPatch();\n     const diffs = dmp.diff_main(a, b);\n     dmp.diff_cleanupSemantic(diffs);\n   \n     let insertions = 0;\n     let deletions  = 0;\n   \n     diffs.forEach(([op, txt]) => {\n       const delta = txt.trim().split(/\\s+/).filter(Boolean).length;\n       if (op ===  1) insertions += delta;  // added in b\n       if (op === -1) deletions  += delta;  // removed from a\n     });\n   \n     return {\n       distance   : dmp.diff_levenshtein(diffs),\n       insertions,\n       deletions,\n     };\n   };\n   "],"mappings":"AAAA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEG,MAAMA,QAAQ,GAAGC,OAAO,CAAC,UAAU,CAAC,CAAC,CAAQ;AAC7C,MAAMC,EAAE,GAASD,OAAO,CAAC,gBAAgB,CAAC,CAAC,CAAE;AAC7C,MAAME,IAAI,GAAOF,OAAO,CAAC,aAAa,CAAC;AACvC,MAAMG,cAAc,GAAGH,OAAO,CAAC,kBAAkB,CAAC;;AAElD;AACA,MAAMI,OAAO,GAAGA,CAACC,GAAG,EAAEC,GAAG,KAAMA,GAAG,GAAGD,GAAG,GAAGC,GAAG,GAAG,CAAE;;AAEnD;AACH;AACA;AACGC,OAAO,CAACC,WAAW,GAAG,CAACC,GAAG,GAAG,EAAE,KAAK;EAClC,MAAMC,KAAK,GAAOD,GAAG,CAACE,IAAI,CAAC,CAAC,CAACC,KAAK,CAAC,KAAK,CAAC,CAACC,MAAM,CAACC,OAAO,CAAC;EACzD,MAAMC,SAAS,GAAGN,GAAG,CAACG,KAAK,CAAC,QAAQ,CAAC,CAACC,MAAM,CAACC,OAAO,CAAC;EACrD,MAAME,eAAe,GAAMP,GAAG,CAACQ,MAAM;EACrC,MAAMC,kBAAkB,GAAGT,GAAG,CAACU,OAAO,CAAC,MAAM,EAAE,EAAE,CAAC,CAACF,MAAM;EACzD,MAAMG,aAAa,GAAQV,KAAK,CAACW,MAAM,CAAC,CAACC,GAAG,EAAEC,CAAC,KAAKD,GAAG,GAAGvB,QAAQ,CAACwB,CAAC,CAAC,EAAE,CAAC,CAAC;;EAEzE;EACA,MAAMC,OAAO,GAAGvB,EAAE,CAAC;IACjBwB,QAAQ,EAAGV,SAAS,CAACE,MAAM,IAAI,CAAC;IAChCS,IAAI,EAAOhB,KAAK,CAACO,MAAM,IAAS,CAAC;IACjClB,QAAQ,EAAGqB,aAAa,IAAQ;EAClC,CAAC,CAAC;;EAEF;EACA,MAAMO,OAAO,GACX,OAAO,GACP,KAAK,GAAGvB,OAAO,CAACM,KAAK,CAACO,MAAM,EAAMF,SAAS,CAACE,MAAM,IAAI,CAAC,CAAC,GACxD,IAAI,GAAIb,OAAO,CAACgB,aAAa,EAAKV,KAAK,CAACO,MAAM,IAAQ,CAAC,CAAC;EAE1D,OAAO;IACL;IACAW,iBAAiB,EAAKC,MAAM,CAACF,OAAO,CAACG,OAAO,CAAC,CAAC,CAAC,CAAC;IAChDC,kBAAkB,EAAIF,MAAM,CAACL,OAAO,CAACM,OAAO,CAAC,CAAC,CAAC,CAAC;IAEhD;IACAE,cAAc,EAAQ5B,OAAO,CAACF,IAAI,CAACQ,KAAK,CAAC,CAACO,MAAM,EAAEP,KAAK,CAACO,MAAM,CAAC;IAC/DgB,SAAS,EAAavB,KAAK,CAACO,MAAM;IAClCiB,WAAW,EAAWhC,IAAI,CAACQ,KAAK,CAAC,CAACO,MAAM;IACxCkB,aAAa,EAASpB,SAAS,CAACE,MAAM;IACtCmB,iBAAiB,EAAKP,MAAM,CAC1BzB,OAAO,CAACM,KAAK,CAACO,MAAM,EAAEF,SAAS,CAACE,MAAM,IAAI,CAAC,CAAC,CAACa,OAAO,CAAC,CAAC,CACxD,CAAC;IAED;IACAd,eAAe;IACfE,kBAAkB;IAClBmB,eAAe,EAAOR,MAAM,CAC1BzB,OAAO,CAACc,kBAAkB,EAAER,KAAK,CAACO,MAAM,IAAI,CAAC,CAAC,CAACa,OAAO,CAAC,CAAC,CAC1D,CAAC;IAED;IACAV,aAAa;IACbkB,mBAAmB,EAAGT,MAAM,CAC1BzB,OAAO,CAACgB,aAAa,EAAEV,KAAK,CAACO,MAAM,IAAI,CAAC,CAAC,CAACa,OAAO,CAAC,CAAC,CACrD;EACF,CAAC;AACH,CAAC;;AAED;AACH;AACA;AACGvB,OAAO,CAACgC,SAAS,GAAG,CAACC,CAAC,GAAG,EAAE,EAAEC,CAAC,GAAG,EAAE,KAAK;EACtC,MAAMC,GAAG,GAAK,IAAIvC,cAAc,CAAC,CAAC;EAClC,MAAMwC,KAAK,GAAGD,GAAG,CAACE,SAAS,CAACJ,CAAC,EAAEC,CAAC,CAAC;EACjCC,GAAG,CAACG,oBAAoB,CAACF,KAAK,CAAC;EAE/B,IAAIG,UAAU,GAAG,CAAC;EAClB,IAAIC,SAAS,GAAI,CAAC;EAElBJ,KAAK,CAACK,OAAO,CAAC,CAAC,CAACC,EAAE,EAAExC,GAAG,CAAC,KAAK;IAC3B,MAAMyC,KAAK,GAAGzC,GAAG,CAACE,IAAI,CAAC,CAAC,CAACC,KAAK,CAAC,KAAK,CAAC,CAACC,MAAM,CAACC,OAAO,CAAC,CAACG,MAAM;IAC5D,IAAIgC,EAAE,KAAM,CAAC,EAAEH,UAAU,IAAII,KAAK,CAAC,CAAE;IACrC,IAAID,EAAE,KAAK,CAAC,CAAC,EAAEF,SAAS,IAAKG,KAAK,CAAC,CAAE;EACvC,CAAC,CAAC;EAEF,OAAO;IACLC,QAAQ,EAAKT,GAAG,CAACU,gBAAgB,CAACT,KAAK,CAAC;IACxCG,UAAU;IACVC;EACF,CAAC;AACH,CAAC","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}