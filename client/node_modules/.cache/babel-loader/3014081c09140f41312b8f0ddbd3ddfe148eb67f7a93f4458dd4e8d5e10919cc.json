{"ast":null,"code":"// const syllable = require(\"syllable\");         // npm i syllable\n// const flesch   = require(\"flesch-kincaid\");   // npm i flesch-kincaid\n// const uniq     = require(\"lodash/uniq\");\n// exports.calcMetrics = (txt = \"\") => {\n//   const words       = txt.trim().split(/\\s+/).filter(Boolean);\n//   const sentences   = txt.split(/[.!?]+/).filter(Boolean);\n//   const chars       = txt.length;\n//   const charsNoSp   = txt.replace(/\\s+/g, \"\").length;\n//   const syllables   = words.reduce((s, w) => s + syllable(w), 0);\n//   const fk          = flesch({ sentence: sentences.length || 1,\n//                                word: words.length || 1,\n//                                syllable: syllables || 1 });\n//   return {\n//     fleschReadingEase:  fk.ease,\n//     fleschKincaidGrade: fk.grade,\n//     lexicalDensity:     uniq(words).length / words.length || 0,\n//     wordCount:          words.length,\n//     uniqueWords:        uniq(words).length,\n//     sentenceCount:      sentences.length,\n//     avgSentenceLength:  words.length / (sentences.length || 1),\n//     charsWithSpaces:    chars,\n//     charsWithoutSpaces: charsNoSp,\n//     avgCharsPerWord:    charsNoSp / (words.length || 1),\n//     syllableCount:      syllables,\n//     avgSyllablesPerWord: syllables / (words.length || 1),\n//   };\n// };\n// exports.diffStats = (a = \"\", b = \"\") => {\n//   const dmp   = new (require(\"diff-match-patch\"))();\n//   const diffs = dmp.diff_main(a, b);\n//   dmp.diff_cleanupSemantic(diffs);\n//   let insertions = 0,\n//       deletions  = 0;\n//   diffs.forEach(([op, txt]) => {\n//     if (op === 1) insertions += txt.trim().split(/\\s+/).length;\n//     if (op === -1) deletions  += txt.trim().split(/\\s+/).length;\n//   });\n//   return {\n//     distance: dmp.diff_levenshtein(diffs),\n//     insertions,\n//     deletions,\n//   };\n// };\n/* utils/textMetrics.js\n   ------------------------------------------------------------------------ *///  const { fleschKincaid: fk } = require('flesch-kincaid');\nconst raw=require(\"syllable\");// whatever shape it is\n/* 🔹 one line that never fails */const syllable=typeof raw===\"function\"?raw:raw.default||raw.syllable||(()=>0);// fallback = dummy fn\n//  const fk    = require(\"flesch-kincaid\");\nconst rawFk=require(\"flesch-kincaid\");// const fk =\n//   typeof rawFk === \"function\"\n//     ? rawFk\n//     : rawFk.default || rawFk.fk || (() => 0);   \nconst fk=typeof rawFk===\"function\"&&rawFk// (old CJS build)\n||rawFk.fleschKincaid// ← correct property\n||rawFk.default// (transpiled ESM)\n||(()=>0);// last‑ditch fallback\nconst uniq=require(\"lodash/uniq\");const DMP=require(\"diff-match-patch\");/* safe division to avoid NaN / Infinity */const div=(n,d)=>d?n/d:0;/* ---------------------------------------------------------------------- */exports.calcMetrics=function(){let txt=arguments.length>0&&arguments[0]!==undefined?arguments[0]:\"\";const words=txt.trim().split(/\\s+/).filter(Boolean);const sentences=txt.split(/[.!?]+/).filter(Boolean);const charsWS=txt.length;const charsNoWS=txt.replace(/\\s+/g,\"\").length;const syllables=words.reduce((s,w)=>s+syllable(w),0);/* FK grade from package */const fkGrade=fk({sentence:sentences.length||1,word:words.length||1,syllable:syllables||1});/* FRE ease – manual formula */const freEase=206.835-1.015*div(words.length,sentences.length||1)-84.6*div(syllables,words.length||1);return{fleschReadingEase:+freEase.toFixed(2),fleschKincaidGrade:+fkGrade.toFixed(2),lexicalDensity:div(uniq(words).length,words.length),wordCount:words.length,uniqueWords:uniq(words).length,sentenceCount:sentences.length,avgSentenceLength:+div(words.length,sentences.length||1).toFixed(2),charsWithSpaces:charsWS,charsWithoutSpaces:charsNoWS,avgCharsPerWord:+div(charsNoWS,words.length||1).toFixed(2),syllableCount:syllables,avgSyllablesPerWord:+div(syllables,words.length||1).toFixed(2)};};/* ---------------------------------------------------------------------- */exports.diffStats=function(){let a=arguments.length>0&&arguments[0]!==undefined?arguments[0]:\"\";let b=arguments.length>1&&arguments[1]!==undefined?arguments[1]:\"\";const dmp=new DMP();const diffs=dmp.diff_main(a,b);dmp.diff_cleanupSemantic(diffs);let insertions=0,deletions=0;diffs.forEach(_ref=>{let[op,txt]=_ref;const delta=txt.trim().split(/\\s+/).filter(Boolean).length;if(op===1)insertions+=delta;if(op===-1)deletions+=delta;});return{distance:dmp.diff_levenshtein(diffs),insertions,deletions};};/* utils/textMetrics.js\n   -------------------------------------------------------------------------- *///  const _syllable = require(\"syllable\");            // ≥4.x is ESM‑only\n//  /* if it's an ESM default export grab it, otherwise use the value directly */\n//  const syllable  = typeof _syllable === \"function\" ? _syllable : _syllable.default;\n//  const fk        = require(\"flesch-kincaid\");\n//  const uniq      = require(\"lodash/uniq\");\n//  const DiffMatchPatch = require(\"diff-match-patch\");\n//  /* small helper for safe division (avoids NaN / Infinity) */\n//  const safeDiv = (num, den) => (den ? num / den : 0);\n//  /* --------------------------------------------------------------------------\n//   * MAIN TEXT‑METRIC AGGREGATOR\n//   * ------------------------------------------------------------------------ */\n//  exports.calcMetrics = (txt = \"\") => {\n//    const words     = txt.trim().split(/\\s+/).filter(Boolean);\n//    const sentences = txt.split(/[.!?]+/).filter(Boolean);\n//    const charsWithSpaces    = txt.length;\n//    const charsWithoutSpaces = txt.replace(/\\s+/g, \"\").length;\n//    const syllableCount      = words.reduce((acc, w) => acc + syllable(w), 0);\n//    /* FK grade – package returns only grade level */\n//    const fkGrade = fk({\n//      sentence : sentences.length || 1,\n//      word     : words.length      || 1,\n//      syllable : syllableCount     || 1,\n//    });\n//    /* Flesch‑Reading‑Ease – compute ourselves */\n//    const freEase =\n//      206.835 -\n//      1.015 * safeDiv(words.length,     sentences.length || 1) -\n//      84.6  * safeDiv(syllableCount,    words.length     || 1);\n//    return {\n//      /* headline readability scores */\n//      fleschReadingEase   : Number(freEase.toFixed(2)),\n//      fleschKincaidGrade  : Number(fkGrade.toFixed(2)),\n//      /* lexical / structural stats */\n//      lexicalDensity      : safeDiv(uniq(words).length, words.length),\n//      wordCount           : words.length,\n//      uniqueWords         : uniq(words).length,\n//      sentenceCount       : sentences.length,\n//      avgSentenceLength   : Number(\n//        safeDiv(words.length, sentences.length || 1).toFixed(2)\n//      ),\n//      /* character‑level stats */\n//      charsWithSpaces,\n//      charsWithoutSpaces,\n//      avgCharsPerWord     : Number(\n//        safeDiv(charsWithoutSpaces, words.length || 1).toFixed(2)\n//      ),\n//      /* syllable‑level stats */\n//      syllableCount,\n//      avgSyllablesPerWord : Number(\n//        safeDiv(syllableCount, words.length || 1).toFixed(2)\n//      ),\n//    };\n//  };\n//  /* --------------------------------------------------------------------------\n//   * DIFF‑BASED EDIT DISTANCE / INSERTIONS / DELETIONS\n//   * ------------------------------------------------------------------------ */\n//  exports.diffStats = (a = \"\", b = \"\") => {\n//    const dmp   = new DiffMatchPatch();\n//    const diffs = dmp.diff_main(a, b);\n//    dmp.diff_cleanupSemantic(diffs);\n//    let insertions = 0;\n//    let deletions  = 0;\n//    diffs.forEach(([op, txt]) => {\n//      const delta = txt.trim().split(/\\s+/).filter(Boolean).length;\n//      if (op ===  1) insertions += delta;  // added in b\n//      if (op === -1) deletions  += delta;  // removed from a\n//    });\n//    return {\n//      distance   : dmp.diff_levenshtein(diffs),\n//      insertions,\n//      deletions,\n//    };\n//  };","map":{"version":3,"names":["raw","require","syllable","default","rawFk","fk","fleschKincaid","uniq","DMP","div","n","d","exports","calcMetrics","txt","arguments","length","undefined","words","trim","split","filter","Boolean","sentences","charsWS","charsNoWS","replace","syllables","reduce","s","w","fkGrade","sentence","word","freEase","fleschReadingEase","toFixed","fleschKincaidGrade","lexicalDensity","wordCount","uniqueWords","sentenceCount","avgSentenceLength","charsWithSpaces","charsWithoutSpaces","avgCharsPerWord","syllableCount","avgSyllablesPerWord","diffStats","a","b","dmp","diffs","diff_main","diff_cleanupSemantic","insertions","deletions","forEach","_ref","op","delta","distance","diff_levenshtein"],"sources":["/Users/anukumar/Desktop/Summer 2025/TextSimplification_CHI/updated_repo/textsimplification/client/src/utils/textMetrics.js"],"sourcesContent":["// const syllable = require(\"syllable\");         // npm i syllable\n// const flesch   = require(\"flesch-kincaid\");   // npm i flesch-kincaid\n// const uniq     = require(\"lodash/uniq\");\n\n// exports.calcMetrics = (txt = \"\") => {\n//   const words       = txt.trim().split(/\\s+/).filter(Boolean);\n//   const sentences   = txt.split(/[.!?]+/).filter(Boolean);\n//   const chars       = txt.length;\n//   const charsNoSp   = txt.replace(/\\s+/g, \"\").length;\n//   const syllables   = words.reduce((s, w) => s + syllable(w), 0);\n\n//   const fk          = flesch({ sentence: sentences.length || 1,\n//                                word: words.length || 1,\n//                                syllable: syllables || 1 });\n\n//   return {\n//     fleschReadingEase:  fk.ease,\n//     fleschKincaidGrade: fk.grade,\n//     lexicalDensity:     uniq(words).length / words.length || 0,\n//     wordCount:          words.length,\n//     uniqueWords:        uniq(words).length,\n//     sentenceCount:      sentences.length,\n//     avgSentenceLength:  words.length / (sentences.length || 1),\n//     charsWithSpaces:    chars,\n//     charsWithoutSpaces: charsNoSp,\n//     avgCharsPerWord:    charsNoSp / (words.length || 1),\n//     syllableCount:      syllables,\n//     avgSyllablesPerWord: syllables / (words.length || 1),\n//   };\n// };\n\n// exports.diffStats = (a = \"\", b = \"\") => {\n//   const dmp   = new (require(\"diff-match-patch\"))();\n//   const diffs = dmp.diff_main(a, b);\n//   dmp.diff_cleanupSemantic(diffs);\n\n//   let insertions = 0,\n//       deletions  = 0;\n\n//   diffs.forEach(([op, txt]) => {\n//     if (op === 1) insertions += txt.trim().split(/\\s+/).length;\n//     if (op === -1) deletions  += txt.trim().split(/\\s+/).length;\n//   });\n\n//   return {\n//     distance: dmp.diff_levenshtein(diffs),\n//     insertions,\n//     deletions,\n//   };\n// };\n\n/* utils/textMetrics.js\n   ------------------------------------------------------------------------ */\n  //  const { fleschKincaid: fk } = require('flesch-kincaid');\n\n   const raw = require(\"syllable\");                 // whatever shape it is\n   /* 🔹 one line that never fails */\n   const syllable =\n     typeof raw === \"function\"\n       ? raw\n       : raw.default || raw.syllable || (() => 0);  // fallback = dummy fn\n   \n  //  const fk    = require(\"flesch-kincaid\");\n\n   const rawFk = require(\"flesch-kincaid\");\n\n// const fk =\n//   typeof rawFk === \"function\"\n//     ? rawFk\n//     : rawFk.default || rawFk.fk || (() => 0);   \n\n  const fk =\n  (typeof rawFk === \"function\" && rawFk)      // (old CJS build)\n  || rawFk.fleschKincaid                      // ← correct property\n  || rawFk.default                            // (transpiled ESM)\n  || (() => 0);                               // last‑ditch fallback\n\n   const uniq  = require(\"lodash/uniq\");\n   const DMP   = require(\"diff-match-patch\");\n   \n   /* safe division to avoid NaN / Infinity */\n   const div = (n, d) => (d ? n / d : 0);\n   \n   /* ---------------------------------------------------------------------- */\n   exports.calcMetrics = (txt = \"\") => {\n     const words      = txt.trim().split(/\\s+/).filter(Boolean);\n     const sentences  = txt.split(/[.!?]+/).filter(Boolean);\n     const charsWS    = txt.length;\n     const charsNoWS  = txt.replace(/\\s+/g, \"\").length;\n     const syllables  = words.reduce((s, w) => s + syllable(w), 0);\n   \n     /* FK grade from package */\n     const fkGrade = fk({\n       sentence : sentences.length || 1,\n       word     : words.length     || 1,\n       syllable : syllables        || 1,\n     });\n   \n     /* FRE ease – manual formula */\n     const freEase =\n       206.835 -\n       1.015 * div(words.length, sentences.length || 1) -\n       84.6  * div(syllables,   words.length     || 1);\n   \n     return {\n       fleschReadingEase   : +freEase.toFixed(2),\n       fleschKincaidGrade  : +fkGrade.toFixed(2),\n       lexicalDensity      : div(uniq(words).length, words.length),\n       wordCount           : words.length,\n       uniqueWords         : uniq(words).length,\n       sentenceCount       : sentences.length,\n       avgSentenceLength   : +div(words.length, sentences.length || 1).toFixed(2),\n       charsWithSpaces     : charsWS,\n       charsWithoutSpaces  : charsNoWS,\n       avgCharsPerWord     : +div(charsNoWS, words.length || 1).toFixed(2),\n       syllableCount       : syllables,\n       avgSyllablesPerWord : +div(syllables, words.length || 1).toFixed(2),\n     };\n   };\n   \n   /* ---------------------------------------------------------------------- */\n   exports.diffStats = (a = \"\", b = \"\") => {\n     const dmp   = new DMP();\n     const diffs = dmp.diff_main(a, b);\n     dmp.diff_cleanupSemantic(diffs);\n   \n     let insertions = 0,\n         deletions  = 0;\n   \n     diffs.forEach(([op, txt]) => {\n       const delta = txt.trim().split(/\\s+/).filter(Boolean).length;\n       if (op ===  1) insertions += delta;\n       if (op === -1) deletions  += delta;\n     });\n   \n     return {\n       distance   : dmp.diff_levenshtein(diffs),\n       insertions,\n       deletions,\n     };\n   };\n   \n/* utils/textMetrics.js\n   -------------------------------------------------------------------------- */\n\n  //  const _syllable = require(\"syllable\");            // ≥4.x is ESM‑only\n  //  /* if it's an ESM default export grab it, otherwise use the value directly */\n  //  const syllable  = typeof _syllable === \"function\" ? _syllable : _syllable.default;\n   \n  //  const fk        = require(\"flesch-kincaid\");\n  //  const uniq      = require(\"lodash/uniq\");\n  //  const DiffMatchPatch = require(\"diff-match-patch\");\n   \n  //  /* small helper for safe division (avoids NaN / Infinity) */\n  //  const safeDiv = (num, den) => (den ? num / den : 0);\n   \n  //  /* --------------------------------------------------------------------------\n  //   * MAIN TEXT‑METRIC AGGREGATOR\n  //   * ------------------------------------------------------------------------ */\n  //  exports.calcMetrics = (txt = \"\") => {\n  //    const words     = txt.trim().split(/\\s+/).filter(Boolean);\n  //    const sentences = txt.split(/[.!?]+/).filter(Boolean);\n  //    const charsWithSpaces    = txt.length;\n  //    const charsWithoutSpaces = txt.replace(/\\s+/g, \"\").length;\n  //    const syllableCount      = words.reduce((acc, w) => acc + syllable(w), 0);\n   \n  //    /* FK grade – package returns only grade level */\n  //    const fkGrade = fk({\n  //      sentence : sentences.length || 1,\n  //      word     : words.length      || 1,\n  //      syllable : syllableCount     || 1,\n  //    });\n   \n  //    /* Flesch‑Reading‑Ease – compute ourselves */\n  //    const freEase =\n  //      206.835 -\n  //      1.015 * safeDiv(words.length,     sentences.length || 1) -\n  //      84.6  * safeDiv(syllableCount,    words.length     || 1);\n   \n  //    return {\n  //      /* headline readability scores */\n  //      fleschReadingEase   : Number(freEase.toFixed(2)),\n  //      fleschKincaidGrade  : Number(fkGrade.toFixed(2)),\n   \n  //      /* lexical / structural stats */\n  //      lexicalDensity      : safeDiv(uniq(words).length, words.length),\n  //      wordCount           : words.length,\n  //      uniqueWords         : uniq(words).length,\n  //      sentenceCount       : sentences.length,\n  //      avgSentenceLength   : Number(\n  //        safeDiv(words.length, sentences.length || 1).toFixed(2)\n  //      ),\n   \n  //      /* character‑level stats */\n  //      charsWithSpaces,\n  //      charsWithoutSpaces,\n  //      avgCharsPerWord     : Number(\n  //        safeDiv(charsWithoutSpaces, words.length || 1).toFixed(2)\n  //      ),\n   \n  //      /* syllable‑level stats */\n  //      syllableCount,\n  //      avgSyllablesPerWord : Number(\n  //        safeDiv(syllableCount, words.length || 1).toFixed(2)\n  //      ),\n  //    };\n  //  };\n   \n  //  /* --------------------------------------------------------------------------\n  //   * DIFF‑BASED EDIT DISTANCE / INSERTIONS / DELETIONS\n  //   * ------------------------------------------------------------------------ */\n  //  exports.diffStats = (a = \"\", b = \"\") => {\n  //    const dmp   = new DiffMatchPatch();\n  //    const diffs = dmp.diff_main(a, b);\n  //    dmp.diff_cleanupSemantic(diffs);\n   \n  //    let insertions = 0;\n  //    let deletions  = 0;\n   \n  //    diffs.forEach(([op, txt]) => {\n  //      const delta = txt.trim().split(/\\s+/).filter(Boolean).length;\n  //      if (op ===  1) insertions += delta;  // added in b\n  //      if (op === -1) deletions  += delta;  // removed from a\n  //    });\n   \n  //    return {\n  //      distance   : dmp.diff_levenshtein(diffs),\n  //      insertions,\n  //      deletions,\n  //    };\n  //  };\n   "],"mappings":"AAAA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA,8EACE;AAEC,KAAM,CAAAA,GAAG,CAAGC,OAAO,CAAC,UAAU,CAAC,CAAkB;AACjD,kCACA,KAAM,CAAAC,QAAQ,CACZ,MAAO,CAAAF,GAAG,GAAK,UAAU,CACrBA,GAAG,CACHA,GAAG,CAACG,OAAO,EAAIH,GAAG,CAACE,QAAQ,GAAK,IAAM,CAAC,CAAC,CAAG;AAElD;AAEC,KAAM,CAAAE,KAAK,CAAGH,OAAO,CAAC,gBAAgB,CAAC,CAE1C;AACA;AACA;AACA;AAEE,KAAM,CAAAI,EAAE,CACP,MAAO,CAAAD,KAAK,GAAK,UAAU,EAAIA,KAAY;AAAA,EACzCA,KAAK,CAACE,aAAmC;AAAA,EACzCF,KAAK,CAACD,OAAmC;AAAA,GACxC,IAAM,CAAC,CAAC,CAAgC;AAE3C,KAAM,CAAAI,IAAI,CAAIN,OAAO,CAAC,aAAa,CAAC,CACpC,KAAM,CAAAO,GAAG,CAAKP,OAAO,CAAC,kBAAkB,CAAC,CAEzC,2CACA,KAAM,CAAAQ,GAAG,CAAGA,CAACC,CAAC,CAAEC,CAAC,GAAMA,CAAC,CAAGD,CAAC,CAAGC,CAAC,CAAG,CAAE,CAErC,4EACAC,OAAO,CAACC,WAAW,CAAG,UAAc,IAAb,CAAAC,GAAG,CAAAC,SAAA,CAAAC,MAAA,IAAAD,SAAA,MAAAE,SAAA,CAAAF,SAAA,IAAG,EAAE,CAC7B,KAAM,CAAAG,KAAK,CAAQJ,GAAG,CAACK,IAAI,CAAC,CAAC,CAACC,KAAK,CAAC,KAAK,CAAC,CAACC,MAAM,CAACC,OAAO,CAAC,CAC1D,KAAM,CAAAC,SAAS,CAAIT,GAAG,CAACM,KAAK,CAAC,QAAQ,CAAC,CAACC,MAAM,CAACC,OAAO,CAAC,CACtD,KAAM,CAAAE,OAAO,CAAMV,GAAG,CAACE,MAAM,CAC7B,KAAM,CAAAS,SAAS,CAAIX,GAAG,CAACY,OAAO,CAAC,MAAM,CAAE,EAAE,CAAC,CAACV,MAAM,CACjD,KAAM,CAAAW,SAAS,CAAIT,KAAK,CAACU,MAAM,CAAC,CAACC,CAAC,CAAEC,CAAC,GAAKD,CAAC,CAAG3B,QAAQ,CAAC4B,CAAC,CAAC,CAAE,CAAC,CAAC,CAE7D,2BACA,KAAM,CAAAC,OAAO,CAAG1B,EAAE,CAAC,CACjB2B,QAAQ,CAAGT,SAAS,CAACP,MAAM,EAAI,CAAC,CAChCiB,IAAI,CAAOf,KAAK,CAACF,MAAM,EAAQ,CAAC,CAChCd,QAAQ,CAAGyB,SAAS,EAAW,CACjC,CAAC,CAAC,CAEF,+BACA,KAAM,CAAAO,OAAO,CACX,OAAO,CACP,KAAK,CAAGzB,GAAG,CAACS,KAAK,CAACF,MAAM,CAAEO,SAAS,CAACP,MAAM,EAAI,CAAC,CAAC,CAChD,IAAI,CAAIP,GAAG,CAACkB,SAAS,CAAIT,KAAK,CAACF,MAAM,EAAQ,CAAC,CAAC,CAEjD,MAAO,CACLmB,iBAAiB,CAAK,CAACD,OAAO,CAACE,OAAO,CAAC,CAAC,CAAC,CACzCC,kBAAkB,CAAI,CAACN,OAAO,CAACK,OAAO,CAAC,CAAC,CAAC,CACzCE,cAAc,CAAQ7B,GAAG,CAACF,IAAI,CAACW,KAAK,CAAC,CAACF,MAAM,CAAEE,KAAK,CAACF,MAAM,CAAC,CAC3DuB,SAAS,CAAarB,KAAK,CAACF,MAAM,CAClCwB,WAAW,CAAWjC,IAAI,CAACW,KAAK,CAAC,CAACF,MAAM,CACxCyB,aAAa,CAASlB,SAAS,CAACP,MAAM,CACtC0B,iBAAiB,CAAK,CAACjC,GAAG,CAACS,KAAK,CAACF,MAAM,CAAEO,SAAS,CAACP,MAAM,EAAI,CAAC,CAAC,CAACoB,OAAO,CAAC,CAAC,CAAC,CAC1EO,eAAe,CAAOnB,OAAO,CAC7BoB,kBAAkB,CAAInB,SAAS,CAC/BoB,eAAe,CAAO,CAACpC,GAAG,CAACgB,SAAS,CAAEP,KAAK,CAACF,MAAM,EAAI,CAAC,CAAC,CAACoB,OAAO,CAAC,CAAC,CAAC,CACnEU,aAAa,CAASnB,SAAS,CAC/BoB,mBAAmB,CAAG,CAACtC,GAAG,CAACkB,SAAS,CAAET,KAAK,CAACF,MAAM,EAAI,CAAC,CAAC,CAACoB,OAAO,CAAC,CAAC,CACpE,CAAC,CACH,CAAC,CAED,4EACAxB,OAAO,CAACoC,SAAS,CAAG,UAAoB,IAAnB,CAAAC,CAAC,CAAAlC,SAAA,CAAAC,MAAA,IAAAD,SAAA,MAAAE,SAAA,CAAAF,SAAA,IAAG,EAAE,IAAE,CAAAmC,CAAC,CAAAnC,SAAA,CAAAC,MAAA,IAAAD,SAAA,MAAAE,SAAA,CAAAF,SAAA,IAAG,EAAE,CACjC,KAAM,CAAAoC,GAAG,CAAK,GAAI,CAAA3C,GAAG,CAAC,CAAC,CACvB,KAAM,CAAA4C,KAAK,CAAGD,GAAG,CAACE,SAAS,CAACJ,CAAC,CAAEC,CAAC,CAAC,CACjCC,GAAG,CAACG,oBAAoB,CAACF,KAAK,CAAC,CAE/B,GAAI,CAAAG,UAAU,CAAG,CAAC,CACdC,SAAS,CAAI,CAAC,CAElBJ,KAAK,CAACK,OAAO,CAACC,IAAA,EAAe,IAAd,CAACC,EAAE,CAAE7C,GAAG,CAAC,CAAA4C,IAAA,CACtB,KAAM,CAAAE,KAAK,CAAG9C,GAAG,CAACK,IAAI,CAAC,CAAC,CAACC,KAAK,CAAC,KAAK,CAAC,CAACC,MAAM,CAACC,OAAO,CAAC,CAACN,MAAM,CAC5D,GAAI2C,EAAE,GAAM,CAAC,CAAEJ,UAAU,EAAIK,KAAK,CAClC,GAAID,EAAE,GAAK,CAAC,CAAC,CAAEH,SAAS,EAAKI,KAAK,CACpC,CAAC,CAAC,CAEF,MAAO,CACLC,QAAQ,CAAKV,GAAG,CAACW,gBAAgB,CAACV,KAAK,CAAC,CACxCG,UAAU,CACVC,SACF,CAAC,CACH,CAAC,CAEJ;AACA,gFAEE;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}